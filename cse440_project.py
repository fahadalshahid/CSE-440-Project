# -*- coding: utf-8 -*-
"""CSE440 Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1obTkxevQFOHAsf2zwLsBAMtVcCam1-nv

CSE440: Natural Language Processing II

Project : Online sexism detection

Team Members:
1. Alvi Sakib Orin - 24141164	 [section: 02]
2. Md Imtiaj Ahmed - 24141163  [section: 01]
3. Fahad Al Shahid - 24141187  [section: 01]
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
# %matplotlib inline
# Train test split
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.preprocessing import LabelEncoder
# Text pre-processing
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping
# Modeling
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional

"""Data importing"""

df = pd.read_csv("/content/train_all_tasks.csv") ##Please upload train_all_tasks.csv file to session storage otherwise it will not find the text file
df.head()

df.describe()

df.groupby('label_sexist').describe().T

plt.figure(figsize=(8,6))
sns.countplot(df.label_sexist)
plt.title('The distribution of sexist and not sexist messages')

"""# Storing the data in a variable:"""

text = df['text']
df['label_sexist'] = df['label_sexist'].map({'not sexist': 0, 'sexist': 1})
label = df['label_sexist']

x_train, x_test, y_train, y_test = train_test_split(text, label, test_size=0.2, random_state=50)

# Defining pre-processing parameters
max_len = 100
trunc_type = 'post'
padding_type = 'post'
oov_tok = '<OOV>' # out of vocabulary token
vocab_size = 500

tokenizer = Tokenizer(num_words = vocab_size,
                      char_level = False,
                      oov_token = oov_tok)
tokenizer.fit_on_texts(x_train)

# Get the word_index
word_index = tokenizer.word_index
total_words = len(word_index)
total_words

training_sequences = tokenizer.texts_to_sequences(x_train)
training_padded = pad_sequences(training_sequences,
                                maxlen = max_len,
                                padding = padding_type,
                                truncating = trunc_type)

testing_sequences = tokenizer.texts_to_sequences(x_test)
testing_padded = pad_sequences(testing_sequences,
                               maxlen = max_len,
                               padding = padding_type,
                               truncating = trunc_type)

print('Shape of training tensor: ', training_padded.shape)
print('Shape of testing tensor: ', testing_padded.shape)

# Define parameter
vocab_size = total_words
embedding_dim = 100
drop_value = 0.2
n_dense = 24
# Define Dense Model Architecture
model = Sequential()
model.add(Embedding(vocab_size,
                    embedding_dim,
                    input_length = max_len))
model.add(GlobalAveragePooling1D())
model.add(Dense(24, activation='relu'))
model.add(Dropout(drop_value))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])

def plotting(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    x = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(x, acc, 'b', label='Training acc')
    plt.plot(x, val_acc, 'r', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(x, loss, 'b', label='Training loss')
    plt.plot(x, val_loss, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=3)
history = model.fit(training_padded,
                    y_train,
                    epochs=num_epochs,
                    validation_data=(testing_padded, y_test),
                    callbacks =[early_stop],
                    verbose=2)

loss2,accuracy2 = model.evaluate(training_padded, y_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy2))
loss2,accuracy2 = model.evaluate(testing_padded, y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy2))


plotting(history)

# Define parameter
n_lstm = 128
drop_lstm = 0.2
# Define LSTM Model
model1 = Sequential()
model1.add(Embedding(vocab_size, embedding_dim, input_length=max_len))
model1.add(SpatialDropout1D(drop_lstm))
model1.add(LSTM(n_lstm, return_sequences=False))
model1.add(Dropout(drop_lstm))
model1.add(Dense(1, activation='sigmoid'))
model1.summary()

model1.compile(loss = 'binary_crossentropy',
               optimizer = 'adam',
               metrics = ['accuracy'])

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history2 = model1.fit(training_padded,
                     y_train,
                     epochs=num_epochs,
                     validation_data=(testing_padded, y_test),
                     callbacks =[early_stop],
                     verbose=2)

loss3,accuracy3 = model1.evaluate(training_padded, y_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy3))
loss3,accuracy3 = model1.evaluate(testing_padded, y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy3))


plotting(history2)

#Define Bi-direction LSTM model
model2 = Sequential()
model2.add(Embedding(vocab_size,
                     embedding_dim,
                     input_length = max_len))
model2.add(Bidirectional(LSTM(n_lstm,
                              return_sequences = False)))
model2.add(Dropout(drop_lstm))
model2.add(Dense(1, activation='sigmoid'))
model2.summary()

model2.compile(loss = 'binary_crossentropy',
               optimizer = 'adam',
               metrics=['accuracy'])

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history3 = model2.fit(training_padded,
                     y_train,
                     epochs=num_epochs,
                     validation_data=(testing_padded, y_test),
                     callbacks =[early_stop],
                     verbose=2)

loss4,accuracy4 = model2.evaluate(training_padded, y_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy4))
loss4,accuracy4 = model2.evaluate(testing_padded, y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy4))


plotting(history3)

"""Define GRU Model Architecture"""

model3 = Sequential()
model3.add(Embedding(vocab_size,
                     embedding_dim,
                     input_length = max_len))
model3.add(SpatialDropout1D(0.2))
model3.add(GRU(128, return_sequences = False))
model3.add(Dropout(0.2))
model3.add(Dense(1, activation = 'sigmoid'))

model3.summary()

model3.compile(loss = 'binary_crossentropy',
                       optimizer = 'adam',
                       metrics=['accuracy'])

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history4 = model3.fit(training_padded,
                     y_train,
                     epochs=num_epochs,
                     validation_data=(testing_padded, y_test),
                     callbacks =[early_stop],
                     verbose=2)

loss5,accuracy5 = model3.evaluate(training_padded, y_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy5))
loss5,accuracy5 = model3.evaluate(testing_padded, y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy5))


plotting(history4)

# Comparing the four different models
print(f"Dense model loss and accuracy: {model.evaluate(testing_padded, y_test)} " )
print(f"LSTM model loss and accuracy: {model1.evaluate(testing_padded, y_test)} " )
print(f"Bi-LSTM model loss and accuracy: {model2.evaluate(testing_padded, y_test)} " )
print(f"GRU model loss and accuracy: {model3.evaluate(testing_padded, y_test)}")

"""## Result of TASK-A"""

predict_text = ["Lol Figures, a damn (alleged) kiddie fiddler. SMDH Sad,but that's what happens to children of prostitutes. Never did pay her for that blowjob.","It gets even better when you tell a white knight that she's not going to fuck him. Watching him just bitch out is often hilarious. And yes, we all need to bully these little bitch boys to stamp this shit out."]
def predict_EDOS(predict_text):
  new_seq = tokenizer.texts_to_sequences(predict_text)
  padded = pad_sequences(new_seq,
                         maxlen = max_len,
                         padding = padding_type,
                         truncating = trunc_type)
  return(model2.predict(padded)) ##Using Bi-LSTM Model
predict_EDOS(predict_text)

##Here the first sentence is not sexist and the second sentence is sexist

"""# TASK-B"""

df.head()

df.groupby('label_category').describe().T

label_encoder_taskB = LabelEncoder()

new_label = label_encoder_taskB.fit_transform(df['label_category'])
x1_train, x1_test, y1_train, y1_test = train_test_split(text, new_label, test_size=0.2, random_state=50)

print(new_label)

# Define parameter
n_lstm = 128
drop_lstm = 0.2
# Define LSTM Model
model_b1 = Sequential()
model_b1.add(Embedding(vocab_size, embedding_dim, input_length=max_len))
model_b1.add(SpatialDropout1D(drop_lstm))
model_b1.add(LSTM(n_lstm, return_sequences=False))
model_b1.add(Dropout(drop_lstm))
model_b1.add(Dense(5, activation='sigmoid'))
model_b1.summary()

model_b1.compile(loss = 'sparse_categorical_crossentropy',
               optimizer = 'adam',
               metrics = ['accuracy'])

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history_b1 = model_b1.fit(training_padded,
                     y1_train,
                     epochs=num_epochs,
                     validation_data=(testing_padded, y1_test),
                     callbacks =[early_stop],
                     verbose=2)

loss_b1,accuracy_b1 = model_b1.evaluate(training_padded, y1_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy_b1))
loss_b1,accuracy_b1 = model_b1.evaluate(testing_padded, y1_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy_b1))


plotting(history_b1)

#Define Bi-directional LSTM Model
model_b2 = Sequential()
model_b2.add(Embedding(vocab_size,
                     embedding_dim,
                     input_length = max_len))
model_b2.add(Bidirectional(LSTM(n_lstm,
                              return_sequences = False)))
model_b2.add(Dropout(drop_lstm))
model_b2.add(Dense(5, activation='sigmoid'))
model_b2.summary()

model_b2.compile(loss = 'sparse_categorical_crossentropy',
               optimizer = 'adam',
               metrics = ['accuracy'])

num_epochs = 20
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history_b2 = model_b2.fit(training_padded,
                     y1_train,
                     epochs=num_epochs,
                     validation_data=(testing_padded, y1_test),
                     callbacks =[early_stop],
                     verbose=2)

loss_b2,accuracy_b2 = model_b2.evaluate(training_padded, y1_train, verbose = False)
print("Training Accuracy: {:.4f}".format(accuracy_b2))
loss_b2,accuracy_b2 = model_b2.evaluate(testing_padded, y1_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy_b2))


plotting(history_b2)

# Comparing the two different models

print(f"LSTM model loss and accuracy: {model_b1.evaluate(testing_padded, y1_test)} " )
print(f"Bi-LSTM model loss and accuracy: {model_b2.evaluate(testing_padded, y1_test)} " )

"""# Result of TASK- B"""

predict_text = ["i think the cleanup crew dude is white. cuckasian = caucasian, not cuck asian. cuck asian is redundant, we're all ricecels.", "All the bullshit rape accusations that keep coming out in the media are making men serious begin to hate women. If that bothers you, go complain to these dumb bitches claiming they were raped a billion years ago by Carl Sagan or whatever."]

def predict_EDOS_taskB(predict_text):
  new_seq = tokenizer.texts_to_sequences(predict_text)
  padded = pad_sequences(new_seq,
                         maxlen = max_len,
                         padding = padding_type,
                         truncating = trunc_type)
  return(model_b2.predict(padded)) ##Using Bi-LSTM Model
predict_EDOS_taskB(predict_text)

##Here the first sentence is not sexist and the result is showing 5th(NONE) classification
##The second sentence is sexist and the result is showing 2nd(derogation) classification